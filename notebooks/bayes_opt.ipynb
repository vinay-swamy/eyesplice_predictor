{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "\n",
    "wsize=40\n",
    "\n",
    "def pre_process(path, cut_off=wsize):\n",
    "    col_names=['seqid', 'wstart','wend','ID']+list(range(80))\n",
    "    c_cols=list(range(80))\n",
    "    df=pd.read_csv(path, sep='\\t', header=None, names=col_names)\n",
    "    sl=df[df['ID'].str.contains('SL')].reset_index(drop=True)\n",
    "    el=df[df['ID'].str.contains('EL')].reset_index(drop=True)\n",
    "    intron=df[df['ID'].str.contains('intron')].reset_index(drop=True)\n",
    "    exon=df[df['ID'].str.contains('exon')].reset_index(drop=True)\n",
    "    rev_idx= ['seqid','wstart','wend','ID']+list(range(79,-1,-1))\n",
    "    sl_rev=sl.loc[:,rev_idx]\n",
    "    sl_rev.columns=col_names\n",
    "    all_junc=pd.concat([el, sl_rev]).reset_index(drop=True)\n",
    "    keep_junc=all_junc.loc[:, c_cols].sum(axis=1) >=80\n",
    "    all_junc=all_junc[keep_junc]\n",
    "    keep_exon=exon.loc[:,c_cols].sum(axis=1) >=80\n",
    "    exon=exon[keep_exon]\n",
    "    intron_sums=intron.loc[:,c_cols].sum(axis=1)\n",
    "    intron_sums.quantile([.1,.2,.3,.4,.6,.7,.8,.9, 1])# majority are 0, but i'll keep it up till 20 for sake of completeness.\n",
    "    keep_intron=intron_sums <= 20\n",
    "    intron=intron[keep_intron]\n",
    "\n",
    "    min_count= min(all_junc.ID.str.contains('ref').sum(),\n",
    "                  all_junc.shape[0]-all_junc.ID.str.contains('ref').sum() ,\n",
    "                  intron.shape[0],\n",
    "                  exon.shape[0])\n",
    "    complete_data=pd.concat([all_junc[all_junc['ID'].str.contains('ref')].sample(min_count, ),\n",
    "                             all_junc[~all_junc['ID'].str.contains('ref')].sample(min_count),\n",
    "                             intron.sample(min_count),\n",
    "                             exon.sample(min_count)\n",
    "                            ]).reset_index(drop=True)\n",
    "\n",
    "    lab_col=list()\n",
    "    '''\n",
    "    0=alt_splice junctino\n",
    "    1=no_splice junction\n",
    "    2=exon\n",
    "    3=not exon\n",
    "    '''\n",
    "    for lab in complete_data['ID']:\n",
    "        if 'intron' in lab:\n",
    "            lab_col.append(3)\n",
    "        elif 'exon' in lab:\n",
    "            lab_col.append(2)\n",
    "        elif 'ref' in lab:\n",
    "            lab_col.append(1)\n",
    "        else:\n",
    "            lab_col.append(0)\n",
    "\n",
    "    complete_data['Y']=lab_col\n",
    "    return(complete_data)\n",
    "\n",
    "\n",
    "os.chdir('/Users/vinayswamy/NIH/eyesplice_predictor/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pre_process('data/cleaned_cov/RPE_Fetal.Tissue/HM7FMBBXX_16424750_S70_bp_features.tsv.gz')\n",
    "data_junc=data.query('Y == 0 | Y == 1')\n",
    "x_cols= list(range(80))\n",
    "X=data_junc.loc[:,x_cols]\n",
    "Y=data_junc['Y']\n",
    "X_train, X_test , Y_train, Y_test= train_test_split(X, Y,test_size=.3, random_state=343434) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "learning_rate =0.1,\n",
    "n_estimators=1000,\n",
    "max_depth=4,\n",
    "min_child_weight=6,\n",
    "gamma=0,\n",
    "subsample=0.8,\n",
    "colsample_bytree=0.8,\n",
    "reg_alpha=0.005,\n",
    "reg_lambda\n",
    "objective= 'binary:logistic',\n",
    "nthread=4,\n",
    "scale_pos_weight=1,\n",
    "\n",
    "base\n",
    "learning_rate\"    : [0.05, 0.10, 0.15, 0.20, 0.25, 0.30 ] ,\n",
    " \"max_depth\"        : [ 3, 4, 5, 6, 8, 10, 12, 15],\n",
    " \"min_child_weight\" : [ 1, 3, 5, 7 ],\n",
    " \"gamma\"            : [ 0.0, 0.1, 0.2 , 0.3, 0.4 ],\n",
    " \"colsample_bytree\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "def opti_wrapper_full(n_learning_rate, n_nestimators, n_maxdepth, n_minchild, n_gamme, n_subsample,\n",
    "                 n_colsample, n_regalpha, n_reglambda, n_scalePosWeight):\n",
    "    model= XGBClassifier(learning_rate=n_learning_rate, n_estimators=n_nestimators, \n",
    "                         max_depth=n_maxdepth, min_child_weight=n_minchild, gamma=n_gamme, \n",
    "                         subsample=n_subsample, colsample_bytree=n_colsample, \n",
    "                         reg_alpha=n_regalpha, reg_lambda=n_reglambda, \n",
    "                         scale_pos_weight=n_scalePosWeight, random_state=223232)\n",
    "    score= cross_val_score(model, X_test,Y_test)\n",
    "    return(score)\n",
    "\n",
    "\n",
    "def opti_wrapper_base(n_learning_rate,  n_gamme,n_colsample, n_regalpha):\n",
    "    model= XGBClassifier(learning_rate=n_learning_rate, gamma=n_gamme,colsample_bytree=n_colsample, \n",
    "                         reg_alpha=n_regalpha,random_state=223232)\n",
    "    score= cross_val_score(model, X_train,Y_train, cv=3).mean()\n",
    "    return(score)\n",
    "param_bounds={'n_learning_rate' : (.01, .3),\n",
    "              #'n_maxdepth' : (3,15),\n",
    "              #'n_minchild' : (1,10), \n",
    "              'n_gamme' : (0,.5),\n",
    "              'n_colsample' : (.3,.8 ), \n",
    "              'n_regalpha' : (1e-5, 100)\n",
    "             }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayes_opt import BayesianOptimization\n",
    "optimizer=BayesianOptimization(f=opti_wrapper_base, pbounds=param_bounds, random_state=1234, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | n_cols... |  n_gamme  | n_lear... | n_rega... |\n",
      "-------------------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.7658  \u001b[0m | \u001b[0m 0.3958  \u001b[0m | \u001b[0m 0.3111  \u001b[0m | \u001b[0m 0.1369  \u001b[0m | \u001b[0m 78.54   \u001b[0m |\n",
      "| \u001b[95m 2       \u001b[0m | \u001b[95m 0.7667  \u001b[0m | \u001b[95m 0.69    \u001b[0m | \u001b[95m 0.1363  \u001b[0m | \u001b[95m 0.09017 \u001b[0m | \u001b[95m 80.19   \u001b[0m |\n",
      "| \u001b[95m 3       \u001b[0m | \u001b[95m 0.7673  \u001b[0m | \u001b[95m 0.7791  \u001b[0m | \u001b[95m 0.438   \u001b[0m | \u001b[95m 0.1138  \u001b[0m | \u001b[95m 50.1    \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.7667  \u001b[0m | \u001b[0m 0.6417  \u001b[0m | \u001b[0m 0.3564  \u001b[0m | \u001b[0m 0.1174  \u001b[0m | \u001b[0m 56.12   \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.7661  \u001b[0m | \u001b[0m 0.5515  \u001b[0m | \u001b[0m 0.006884\u001b[0m | \u001b[0m 0.2341  \u001b[0m | \u001b[0m 88.26   \u001b[0m |\n",
      "| \u001b[95m 6       \u001b[0m | \u001b[95m 0.7682  \u001b[0m | \u001b[95m 0.5938  \u001b[0m | \u001b[95m 0.1764  \u001b[0m | \u001b[95m 0.09206 \u001b[0m | \u001b[95m 0.000290\u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.7645  \u001b[0m | \u001b[0m 0.7378  \u001b[0m | \u001b[0m 0.3999  \u001b[0m | \u001b[0m 0.2938  \u001b[0m | \u001b[0m 0.000107\u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.7671  \u001b[0m | \u001b[0m 0.6334  \u001b[0m | \u001b[0m 0.2062  \u001b[0m | \u001b[0m 0.01229 \u001b[0m | \u001b[0m 0.009184\u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.7659  \u001b[0m | \u001b[0m 0.3478  \u001b[0m | \u001b[0m 0.4117  \u001b[0m | \u001b[0m 0.1922  \u001b[0m | \u001b[0m 0.002077\u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m 0.7654  \u001b[0m | \u001b[0m 0.3382  \u001b[0m | \u001b[0m 0.2541  \u001b[0m | \u001b[0m 0.108   \u001b[0m | \u001b[0m 100.0   \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m 0.767   \u001b[0m | \u001b[0m 0.3104  \u001b[0m | \u001b[0m 0.3591  \u001b[0m | \u001b[0m 0.01921 \u001b[0m | \u001b[0m 0.01143 \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m 0.7677  \u001b[0m | \u001b[0m 0.4868  \u001b[0m | \u001b[0m 0.4214  \u001b[0m | \u001b[0m 0.1152  \u001b[0m | \u001b[0m 0.007597\u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m 0.7677  \u001b[0m | \u001b[0m 0.6152  \u001b[0m | \u001b[0m 0.3936  \u001b[0m | \u001b[0m 0.02611 \u001b[0m | \u001b[0m 0.007597\u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m 0.7682  \u001b[0m | \u001b[0m 0.3313  \u001b[0m | \u001b[0m 0.13    \u001b[0m | \u001b[0m 0.09347 \u001b[0m | \u001b[0m 0.01001 \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m 0.7675  \u001b[0m | \u001b[0m 0.7284  \u001b[0m | \u001b[0m 0.008698\u001b[0m | \u001b[0m 0.1136  \u001b[0m | \u001b[0m 0.04907 \u001b[0m |\n",
      "=========================================================================\n"
     ]
    }
   ],
   "source": [
    "params=optimizer.maximize(init_points=5, n_iter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix , roc_auc_score, roc_curve, precision_recall_curve, average_precision_score\n",
    "from xgboost import XGBClassifier\n",
    "import pandas_ml as pml\n",
    "\n",
    "def ROC_plot(Y_test, Y_prob):\n",
    "    fpr, tpr, thresholds=roc_curve(Y_test, Y_prob)\n",
    "    auc=roc_auc_score(Y_test, Y_prob)\n",
    "    # Plot ROC curve\n",
    "    plt.plot(fpr, tpr, label='ROC curve (area = %0.3f)' % auc)\n",
    "    plt.plot([0, 1], [0, 1], 'k--')  # random predictions curve\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.0])\n",
    "    plt.xlabel('False Positive Rate or (1 - Specifity)')\n",
    "    plt.ylabel('True Positive Rate or (Sensitivity)')\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "def PR_plot(Y_test, Y_prob):\n",
    "    pre, rec, thresholds = precision_recall_curve(Y_test, Y_prob)\n",
    "    auc = average_precision_score(Y_test, Y_prob)\n",
    "    plt.plot(rec, pre, label=' Prec/Rec (area = %0.2f)' % ( auc))\n",
    "    plt.plot([1, 1], [1, 1],'r--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title('')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()   \n",
    "\n",
    "def train_model(X,Y, model):\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size=.3, random_state=8976, stratify=Y)\n",
    "    model.fit(X_train, Y_train)\n",
    "    Y_pred=model.predict(X_test)\n",
    "    Y_prob=model.predict_proba(X_test)[:,1]\n",
    "    labs=model.classes_\n",
    "    print('confusion matrix\\n\\n')\n",
    "    print(pd.DataFrame(confusion_matrix(Y_test, Y_pred), index=labs, columns=labs))\n",
    "    print('\\n\\nclassification report\\n\\n')\n",
    "    print(classification_report(y_pred=Y_pred,y_true=Y_test))\n",
    "    #ROC_plot(Y_test , Y_prob)\n",
    "    #PR_plot(Y_test,Y_prob)\n",
    "    return(model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix\n",
      "\n",
      "\n",
      "      0     1\n",
      "0  4815  1632\n",
      "1  1380  5067\n",
      "\n",
      "\n",
      "classification report\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.75      0.76      6447\n",
      "           1       0.76      0.79      0.77      6447\n",
      "\n",
      "   micro avg       0.77      0.77      0.77     12894\n",
      "   macro avg       0.77      0.77      0.77     12894\n",
      "weighted avg       0.77      0.77      0.77     12894\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_cols=list(range(80))\n",
    "model_vanilla=XGBClassifier(random_state=2234)\n",
    "trained_model= train_model(X, Y, model_vanilla)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix\n",
      "\n",
      "\n",
      "      0     1\n",
      "0  4817  1630\n",
      "1  1378  5069\n",
      "\n",
      "\n",
      "classification report\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.75      0.76      6447\n",
      "           1       0.76      0.79      0.77      6447\n",
      "\n",
      "   micro avg       0.77      0.77      0.77     12894\n",
      "   macro avg       0.77      0.77      0.77     12894\n",
      "weighted avg       0.77      0.77      0.77     12894\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_opti=XGBClassifier(colsample_bytree=.5938, gamma=.1764, learning_rate=.09206, reg_alpha=.000290, random_state=343434)\n",
    "tm_opti=train_model(X,Y, model_opti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
