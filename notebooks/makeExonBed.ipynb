{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pybedtools import BedTool\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import random as rd\n",
    "args=sys.argv\n",
    "wd=args[1]\n",
    "ref_gtf_file=args[2]\n",
    "sample_file=args[3]\n",
    "tx_quant_file=args[4]\n",
    "subtissue=args[5]\n",
    "wsize=int(args[6])\n",
    "out_bed_file=args[7]\n",
    "#love stealing my own code \n",
    "def read_GTF(file):\n",
    "    def file_len(fname):\n",
    "        with open(fname) as f:\n",
    "            os=0\n",
    "            for i, l in enumerate(f):\n",
    "                if l[0]=='#':\n",
    "                    os+=1\n",
    "        return ((i + 1 -os , os))\n",
    "\n",
    "    def parse_attributes(st):\n",
    "        att_list=st.replace('\"','').replace('=', ' ').split(';')[:-1]\n",
    "        out_dict=dict()\n",
    "        for att in att_list:\n",
    "            att=att.lstrip(' ').split(' ')\n",
    "            out_dict[att[0]]=att[1]\n",
    "        return(out_dict)\n",
    "    file_length, os=file_len(file)\n",
    "    outdf=[None]*file_length\n",
    "    with open(file) as gtf:\n",
    "        gtf_header=['seqid','source','type','start','end','score','strand','frame']\n",
    "        for k in range(os):\n",
    "            gtf.readline().strip('\\n')\n",
    "        for i in range(file_length):\n",
    "            line= gtf.readline().strip('\\n')\n",
    "            line_list=line.split('\\t')\n",
    "            line_dict=dict()\n",
    "            [line_dict.update({value:line_list[j]}) for j,value in enumerate(gtf_header)]\n",
    "            line_dict.update(parse_attributes(line_list[-1]))\n",
    "            outdf[i]=line_dict\n",
    "    df=[k for k in outdf if k is not None]\n",
    "    df=pd.DataFrame(outdf)\n",
    "    col=df.columns.tolist()\n",
    "    df['start']=pd.to_numeric(df['start'])\n",
    "    df['end']=pd.to_numeric(df['end'])\n",
    "    col=[cn for cn in col if cn not in gtf_header]\n",
    "    df=df[gtf_header+col]\n",
    "    return(df)\n",
    "\n",
    "def bool_to_split(dfs):\n",
    "    rd.seed(8774)\n",
    "    l=[l for l in range(dfs)]\n",
    "    idx=set(rd.sample(l, int(dfs/2)))\n",
    "    idx_bool=[True if i in idx else False for i in l]\n",
    "    return(idx_bool)\n",
    "#not going to worray about account for tpm exp, but just gonna have a exp threshold in prep step\n",
    "os.chdir(wd)\n",
    "# os.chdir('/Users/vinayswamy/NIH/eyesplice_predictor')\n",
    "# wsize=40\n",
    "# ref_gtf_file='ref/gencodeAno_comp.gtf'\n",
    "# sample_file='sampleTableESP.tsv'\n",
    "# tx_quant_file='data/quant/tx_quant.tsv'\n",
    "# subtissue='RPE_Fetal.Tissue'\n",
    "# out_bed_file='complete_windows.bed'\n",
    "\n",
    "sample_table=pd.read_csv(sample_file, sep='\\t', names=['sample', 'run', 'paired', 'tissue', 'subtissue','origin']).query('subtissue == @subtissue')\n",
    "tx_quant=pd.read_csv(tx_quant_file, sep='\\t').loc[:,['transcript_id']+list(sample_table['sample'])]\n",
    "\n",
    "ref_gtf=read_GTF(ref_gtf_file)\n",
    "#ref_gtf=ref_gtf.head(1000)\n",
    "SL_score=111\n",
    "EL_score=222\n",
    "R_SL_score=333\n",
    "R_EL_score=444\n",
    "I_score=555\n",
    "E_score=666"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "A different bed file will be created for each subtissue type, were are only going to build the bed file from expressed transcripts\n",
    "\n",
    "'''\n",
    "keep=(tx_quant\n",
    "      .iloc[:,1:]\n",
    "      .sum(axis=1) >= len(sample_table.index)  \n",
    "    )\n",
    "tx_quant=tx_quant[keep]\n",
    "ref_gtf=ref_gtf[ref_gtf['transcript_id'].isin(tx_quant[\"transcript_id\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "find all exons that that start on the same coordinate, but end on different coordinates. Do the same but end same and start changes. \n",
    "Right now for simplicity sake, Im only selecting alt spliced exons that come in 2 versions\n",
    "end format for these 2 is BED\n",
    "ps peep the pretty new formatting\n",
    "'''\n",
    "\n",
    "end_longer_all=(ref_gtf\n",
    "                .query('type == \"exon\"')\n",
    "                .groupby(['seqid', 'strand', 'start'], as_index=False)\n",
    "                .agg({ 'end':['min', 'max', 'nunique']})\n",
    "                .reset_index(drop=True)\n",
    "               )\n",
    "end_longer_all.columns=['seqid', 'strand', 'start', 'min_end', 'max_end', 'count']\n",
    "end_longer_all=(end_longer_all\n",
    "                .assign(short_length= lambda x: x['min_end'] -x['start'], \n",
    "                        long_length= lambda x: x['max_end'] - x['min_end'])\n",
    "                .rename(columns={'nunique':'count'})\n",
    "                .query('count > 1')\n",
    "               )\n",
    "end_longer= (end_longer_all\n",
    "             .query('count == 2 & short_length >= @wsize & long_length >=@wsize')\n",
    "             .assign(wstart= lambda x: x['min_end']-wsize, \n",
    "                     wend= lambda x: x['min_end']+wsize,\n",
    "                     name = lambda x: ['EL_' + str(i) for i in range(len(x.index))])\n",
    "             .reset_index(drop=True)\n",
    "             .assign(score=EL_score)\n",
    "             .loc[:,['seqid', 'wstart', 'wend', 'name', 'score', 'strand']]\n",
    "            )\n",
    "\n",
    "start_longer_all= (ref_gtf\n",
    "                   .query('type == \"exon\"')\n",
    "                   .groupby(['seqid','strand', 'end'], as_index=False)\n",
    "                   .agg({'start':['min', 'max', 'nunique']})\n",
    "                   .reset_index(drop=True)\n",
    "                  )\n",
    "start_longer_all.columns=['seqid', 'strand', 'end', 'min_start', 'max_start','count' ]\n",
    "start_longer_all=(start_longer_all\n",
    "                  .assign(short_length= lambda x: x['end'] -x['max_start'], \n",
    "                          long_length= lambda x: x['max_start']-x['min_start'])\n",
    "                  .query('count > 1')\n",
    "                 )\n",
    "start_longer= (start_longer_all\n",
    "               .query(\"count == 2 & short_length>= @wsize & long_length >= @wsize\")\n",
    "               .assign(wstart= lambda x: x['max_start']- wsize, \n",
    "                       wend= lambda x: x['max_start'] + wsize , \n",
    "                       name = lambda x: ['SL_' + str(i) for i in range(len(x.index))])\n",
    "               .reset_index(drop=True)\n",
    "               .assign(score=SL_score)\n",
    "               .loc[:,['seqid', 'wstart', 'wend', 'name', 'score', 'strand']]\n",
    "              )\n",
    "alt_spliced_windows=pd.concat([end_longer, start_longer]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seqid</th>\n",
       "      <th>strand</th>\n",
       "      <th>start</th>\n",
       "      <th>min_end</th>\n",
       "      <th>max_end</th>\n",
       "      <th>count</th>\n",
       "      <th>short_length</th>\n",
       "      <th>long_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chr1</td>\n",
       "      <td>+</td>\n",
       "      <td>12613</td>\n",
       "      <td>12697</td>\n",
       "      <td>12721</td>\n",
       "      <td>2</td>\n",
       "      <td>84</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>chr1</td>\n",
       "      <td>+</td>\n",
       "      <td>13221</td>\n",
       "      <td>13374</td>\n",
       "      <td>14409</td>\n",
       "      <td>2</td>\n",
       "      <td>153</td>\n",
       "      <td>1035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>chr1</td>\n",
       "      <td>+</td>\n",
       "      <td>30976</td>\n",
       "      <td>31097</td>\n",
       "      <td>31109</td>\n",
       "      <td>2</td>\n",
       "      <td>121</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>chr1</td>\n",
       "      <td>+</td>\n",
       "      <td>365171</td>\n",
       "      <td>365510</td>\n",
       "      <td>366052</td>\n",
       "      <td>3</td>\n",
       "      <td>339</td>\n",
       "      <td>542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>chr1</td>\n",
       "      <td>+</td>\n",
       "      <td>594235</td>\n",
       "      <td>594574</td>\n",
       "      <td>594768</td>\n",
       "      <td>2</td>\n",
       "      <td>339</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   seqid strand   start  min_end  max_end  count  short_length  long_length\n",
       "3   chr1      +   12613    12697    12721      2            84           24\n",
       "5   chr1      +   13221    13374    14409      2           153         1035\n",
       "11  chr1      +   30976    31097    31109      2           121           12\n",
       "32  chr1      +  365171   365510   366052      3           339          542\n",
       "38  chr1      +  594235   594574   594768      2           339          194"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "end_longer_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vinayswamy/anaconda3/lib/python3.6/site-packages/pybedtools/bedtool.py:3439: FutureWarning: read_table is deprecated, use read_csv instead, passing sep='\\t'.\n",
      "  return pandas.read_table(self.fn, *args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "#********BUG anti_joins are not in pandas (SAD) and the method I'm using can sometimes coerce to int64 to floats, which makes bedtools wig out **********************# \n",
    "'''\n",
    "remove any exons we are using for start/end longer (hence the above problem with antijoins)\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "exon_no_change= (ref_gtf #first, anti_join out known exon locations.\n",
    "                   .query('type == \"exon\"').loc[:,['seqid', 'strand', 'start', 'end']]\n",
    "                   .merge(end_longer_all.loc[:,['seqid','strand', 'start']],\n",
    "                          how='outer',indicator=True)\n",
    "                   .query('_merge ==  \"left_only\"')\n",
    "                   .drop(columns=['_merge'])\n",
    "                   .assign(start= lambda x: x['start'].astype(np.int64),\n",
    "                            end= lambda x: x['end'].astype(np.int64))\n",
    "                   .merge(start_longer_all.loc[:,['seqid','strand','end']], \n",
    "                          how='outer', indicator=True)\n",
    "                   .query('_merge == \"left_only\"')\n",
    "                   .drop(columns=['_merge'])\n",
    "                   .assign(start= lambda x: x['start'].astype(np.int64), \n",
    "                           end= lambda x: x['end'].astype(np.int64),\n",
    "                           name= 'nc', score=I_score)\n",
    "                   .loc[:,['seqid', 'start', 'end', 'name', 'score', 'strand']]\n",
    "                   # I'm concerned that 2 exons might overlap but not share the same start/end so\n",
    "                   # so also going to subtract out any previous windows.\n",
    "                   # make sure to keep only exons that are long enough for our window size.\n",
    "                   .pipe(BedTool.from_dataframe)\n",
    "                   .intersect(alt_spliced_windows.pipe(BedTool.from_dataframe),\n",
    "                            s=True, loj=True)\n",
    "                   .to_dataframe()\n",
    "                   .rename(columns={'chrom':'seqid'})\n",
    "                   .assign(length= lambda x: x['end']-x['start'])\n",
    "                   .query('length >=@wsize & thickEnd == -1 ' )\n",
    "                   .reset_index(drop=True)\n",
    "                   .loc[:,['seqid', 'start', 'end', 'name', 'score', 'strand']]\n",
    "                )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vinayswamy/anaconda3/lib/python3.6/site-packages/pybedtools/bedtool.py:3439: FutureWarning: read_table is deprecated, use read_csv instead, passing sep='\\t'.\n",
      "  return pandas.read_table(self.fn, *args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seqid</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>name</th>\n",
       "      <th>score</th>\n",
       "      <th>strand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chr1</td>\n",
       "      <td>12010</td>\n",
       "      <td>12057</td>\n",
       "      <td>nc</td>\n",
       "      <td>555</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chr1</td>\n",
       "      <td>12975</td>\n",
       "      <td>13052</td>\n",
       "      <td>nc</td>\n",
       "      <td>555</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chr1</td>\n",
       "      <td>24738</td>\n",
       "      <td>24891</td>\n",
       "      <td>nc</td>\n",
       "      <td>555</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chr1</td>\n",
       "      <td>16858</td>\n",
       "      <td>17055</td>\n",
       "      <td>nc</td>\n",
       "      <td>555</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chr1</td>\n",
       "      <td>16607</td>\n",
       "      <td>16765</td>\n",
       "      <td>nc</td>\n",
       "      <td>555</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  seqid  start    end name  score strand\n",
       "0  chr1  12010  12057   nc    555      +\n",
       "1  chr1  12975  13052   nc    555      +\n",
       "2  chr1  24738  24891   nc    555      -\n",
       "3  chr1  16858  17055   nc    555      -\n",
       "4  chr1  16607  16765   nc    555      -"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs=len(exon_no_change.index)\n",
    "spl=np.array(bool_to_split(dfs))\n",
    "exons_for_junc=exon_no_change.iloc[spl].reset_index(drop=True)\n",
    "#junction set first \n",
    "spl_junc=np.array(bool_to_split(len(exons_for_junc.index)))\n",
    "junc_sl=(exons_for_junc\n",
    "         .iloc[spl_junc]\n",
    "         .reset_index(drop=True)\n",
    "         .assign(wstart =lambda x: x['start'] -wsize, \n",
    "                wend=lambda x: x['start']+wsize, \n",
    "                name=lambda x: ['ref_SL_'+str(i) for i in range(len(x.index))],\n",
    "                score=R_SL_score)\n",
    "         .loc[:,['seqid', 'wstart', 'wend', 'name', 'score', 'strand']]\n",
    "        )\n",
    "\n",
    "junc_el=(exons_for_junc\n",
    "         .iloc[~spl_junc]\n",
    "         .reset_index(drop=True)\n",
    "         .assign(wstart=lambda x: x['end'] -wsize, \n",
    "                 wend=lambda x: x['end']+wsize, \n",
    "                 name =lambda x: ['ref_EL_' + str(i) for i in range(len(x.index))],\n",
    "                 score=R_EL_score)\n",
    "         .loc[:,['seqid', 'wstart', 'wend', 'name', 'score', 'strand']]\n",
    "        )\n",
    "\n",
    "\n",
    "ref_altSplice_windows=pd.concat([junc_el, junc_sl]).reset_index(drop=True)\n",
    "\n",
    "#exon_no_change for sure does not overlap at all with with alt_spliced_windows, but it may overlap with ref_alt_windows, so going to anti_join that bish again.\n",
    "exons_for_exon=(exon_no_change\n",
    "                .iloc[~spl]\n",
    "                .reset_index(drop=True)\n",
    "                .pipe(BedTool.from_dataframe)\n",
    "                .intersect(ref_altSplice_windows.pipe(BedTool.from_dataframe),\n",
    "                          s=True, loj=True)\n",
    "                .to_dataframe()\n",
    "                .rename(columns={'chrom':'seqid'})\n",
    "                .query('thickEnd == -1 ')\n",
    "                .loc[:,['seqid', 'start', 'end', 'name', 'score', 'strand']]\n",
    "               )\n",
    "exons_for_exon.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vinayswamy/anaconda3/lib/python3.6/site-packages/pybedtools/bedtool.py:3439: FutureWarning: read_table is deprecated, use read_csv instead, passing sep='\\t'.\n",
      "  return pandas.read_table(self.fn, *args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Now need to get regions of intronic coverage\n",
    "subtract out all known exons from all transcripts, but pad the exons on wither end, st that pad > wsize. This way we are for sure that the intronic region over lap with none of our previous windows\n",
    "    - cant overlap with alt_splcied exons, bc window < long exon end. but fo the ref ones, the pad takes care of it.\n",
    "'''\n",
    "pad=wsize+5\n",
    "ref_txs=(ref_gtf\n",
    "         .query('type == \"transcript\"')\n",
    "         .loc[:,['seqid', 'start','end','transcript_id','score','strand']]\n",
    "         .assign(score=1000)\n",
    "         .reset_index(drop=True)\n",
    "        )\n",
    "\n",
    "ref_exons=(ref_gtf\n",
    "           .query('type == \"exon\"')\n",
    "           .loc[:,['seqid', 'start','end','transcript_id','score','strand']]\n",
    "           .assign(score=1000, \n",
    "                   start= lambda x: x['start'] -pad, \n",
    "                   end = lambda x: x['end'] +pad)\n",
    "           .reset_index(drop=True)\n",
    "          )\n",
    "\n",
    "introns=(ref_txs\n",
    "         .pipe(BedTool.from_dataframe)\n",
    "         .subtract(ref_exons.pipe(BedTool.from_dataframe), \n",
    "                   s=True)\n",
    "         .to_dataframe()\n",
    "         .assign(length=lambda x: x['end']-x['start'])\n",
    "         .query('length >= @wsize*4')# lets make sure were picking from bigger introns\n",
    "         .rename(columns={'chrom':'seqid'})\n",
    "         .reset_index(drop=True)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_random_window(ser, ws=wsize *2):\n",
    "    start=ser[1]\n",
    "    max_wend=ser[2]-ws\n",
    "    wstart=rd.randint(start, max_wend)\n",
    "    wend=wstart+ws\n",
    "    return((wstart, wend))\n",
    "intron_windows=(introns\n",
    "                .apply(make_random_window,axis=1, result_type='expand')\n",
    "                .rename(columns={0:'wstart', 1:'wend'})\n",
    "                .merge(introns,how='left', left_index=True, right_index=True)\n",
    "                .loc[:,['seqid', 'wstart', 'wend', 'name', 'score', 'strand']]\n",
    "                .assign(name = lambda x: ['intron_' + str(i) for i in range(len(x.index))],\n",
    "                        score=I_score)\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25, 6)\n",
      "(149, 6)\n",
      "(588, 6)\n",
      "(70, 6)\n"
     ]
    }
   ],
   "source": [
    "#exon for exon does not overlap with either ref_alt or alt, so don't need to worry about that\n",
    "#also cannot overlap with intron version based on above logic, so don't worry about that either\n",
    "exon_windows= (exons_for_exon.reset_index(drop=True)\n",
    "                .assign(name='x', \n",
    "                        score=E_score,\n",
    "                        length=lambda x: x['end'] - x['start'])\n",
    "                .query('length >= @wsize*2 +1 ') # remove potential windows with\n",
    "              )\n",
    "exon_windows= (exon_windows\n",
    "                .apply(make_random_window, axis=1, result_type='expand')\n",
    "                .rename(columns={0:'wstart', 1:'wend'})\n",
    "                .merge(exon_windows, left_index=True, right_index=True)\n",
    "                .loc[:,['seqid', 'wstart', 'wend', 'name', 'score', 'strand']]\n",
    "                .assign(name=lambda x: ['exon_'+str(i) for i in range(len(x.index))])\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_samps=min(alt_spliced_windows.shape[0], ref_altSplice_windows.shape[0], \n",
    "              intron_windows.shape[0], exon_windows.shape[0])\n",
    "complete_bed=(pd.concat([alt_spliced_windows, \n",
    "                         ref_altSplice_windows.sample(min_samps), \n",
    "                         intron_windows.sample(min_samps), \n",
    "                         exon_windows.sample(min_samps)\n",
    "                        ])\n",
    "              .reset_index(drop=True)\n",
    "             )\n",
    "bad=complete_bed.assign(length= lambda x:x['wend']-x['wstart']).query('length<@wsize*2').shape\n",
    "if bad[0] >0:\n",
    "    print('Warning: {} rows are less than minimum window size')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_bed.to_csv(out_bed_file, header=False, index=False, sep='\\t')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
