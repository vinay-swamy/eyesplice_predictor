{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pybedtools import BedTool\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import random as rd\n",
    "args=sys.argv\n",
    "wd=args[1]\n",
    "ref_gtf_file=args[2]\n",
    "sample_file=args[3]\n",
    "tx_quant_file=args[4]\n",
    "subtissue=args[5]\n",
    "wsize=int(args[6])\n",
    "out_bed_file=args[7]\n",
    "#love stealing my own code \n",
    "def read_GTF(file):\n",
    "    def file_len(fname):\n",
    "        with open(fname) as f:\n",
    "            os=0\n",
    "            for i, l in enumerate(f):\n",
    "                if l[0]=='#':\n",
    "                    os+=1\n",
    "        return ((i + 1 -os , os))\n",
    "\n",
    "    def parse_attributes(st):\n",
    "        att_list=st.replace('\"','').replace('=', ' ').split(';')[:-1]\n",
    "        out_dict=dict()\n",
    "        for att in att_list:\n",
    "            att=att.lstrip(' ').split(' ')\n",
    "            out_dict[att[0]]=att[1]\n",
    "        return(out_dict)\n",
    "    file_length, os=file_len(file)\n",
    "    outdf=[None]*file_length\n",
    "    with open(file) as gtf:\n",
    "        gtf_header=['seqid','source','type','start','end','score','strand','frame']\n",
    "        for k in range(os):\n",
    "            gtf.readline().strip('\\n')\n",
    "        for i in range(file_length):\n",
    "            line= gtf.readline().strip('\\n')\n",
    "            line_list=line.split('\\t')\n",
    "            line_dict=dict()\n",
    "            [line_dict.update({value:line_list[j]}) for j,value in enumerate(gtf_header)]\n",
    "            line_dict.update(parse_attributes(line_list[-1]))\n",
    "            outdf[i]=line_dict\n",
    "    df=[k for k in outdf if k is not None]\n",
    "    df=pd.DataFrame(outdf)\n",
    "    col=df.columns.tolist()\n",
    "    df['start']=pd.to_numeric(df['start'])\n",
    "    df['end']=pd.to_numeric(df['end'])\n",
    "    col=[cn for cn in col if cn not in gtf_header]\n",
    "    df=df[gtf_header+col]\n",
    "    return(df)\n",
    "\n",
    "def bool_to_split(dfs):\n",
    "    rd.seed(8774)\n",
    "    l=[l for l in range(dfs)]\n",
    "    idx=set(rd.sample(l, int(dfs/2)))\n",
    "    idx_bool=[True if i in idx else False for i in l]\n",
    "    return(idx_bool)\n",
    "'''\n",
    "Overall process \n",
    "    -first, find all exons that have an alternative 3'(end longer) or alternative 5'(start_longer)\n",
    "    -create a window where the junciton between the long and short forms is the middle of the window\n",
    "    -\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "os.chdir(wd)\n",
    "#os.chdir('/Users/vinayswamy/NIH/eyesplice_predictor')\n",
    "# wsize=40\n",
    "# ref_gtf_file='ref/gencodeAno_comp.gtf'\n",
    "# sample_file='sampleTableESP.tsv'\n",
    "# tx_quant_file='data/GC_pc_tx_quant.tsv.gz'\n",
    "# subtissue='RPE_Fetal.Tissue'\n",
    "# out_bed_file='testing/new_script_old_txquant.bed'\n",
    "\n",
    "sample_table=pd.read_csv(sample_file, sep='\\t', names=['sample', 'run', 'paired', 'tissue', 'subtissue','origin']).query('subtissue == @subtissue')\n",
    "tx_quant=pd.read_csv(tx_quant_file, sep='\\t')#.loc[:,['transcript_id']+list(sample_table['sample'])]\n",
    "\n",
    "ref_gtf=read_GTF(ref_gtf_file)\n",
    "#ref_gtf=ref_gtf.head(1000)\n",
    "SL_score=111\n",
    "EL_score=222\n",
    "R_SL_score=333\n",
    "R_EL_score=444\n",
    "I_score=555\n",
    "E_score=666"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2693966, 24)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tx_quant.shape\n",
    "ref_gtf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "A different bed file will be created for each subtissue type, were are only going to build the window bed file from transcripts expressed in the target tissue\n",
    "\n",
    "'''\n",
    "keep=(tx_quant\n",
    "      .iloc[:,1:]\n",
    "      .sum(axis=1) > len(sample_table.index)  \n",
    "    )\n",
    "tx_quant=tx_quant[keep]\n",
    "ref_gtf=ref_gtf[ref_gtf['transcript_id'].isin(tx_quant[\"transcript_id\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "find all exons that that start on the same coordinate, but end on different coordinates. Do the same but end same and start changes. \n",
    "Right now for simplicity sake, Im only selecting alt spliced exons that come in 2 versions\n",
    "out format for these 2 is BED\n",
    "\n",
    "'''\n",
    "\n",
    "end_longer_all=(ref_gtf\n",
    "                .query('type == \"exon\"')\n",
    "                .groupby(['seqid', 'strand', 'start'], as_index=False)\n",
    "                .agg({ 'end':['min', 'max', 'nunique']})\n",
    "                .reset_index(drop=True)\n",
    "               )\n",
    "end_longer_all.columns=['seqid', 'strand', 'start', 'min_end', 'max_end', 'count']\n",
    "end_longer_all=(end_longer_all\n",
    "                .assign(short_length= lambda x: x['min_end'] -x['start'], \n",
    "                        long_length= lambda x: x['max_end'] - x['min_end'])\n",
    "                .rename(columns={'nunique':'count'})\n",
    "                .query('count > 1')\n",
    "               )\n",
    "end_longer= (end_longer_all\n",
    "             .query('count == 2 & short_length >= @wsize & long_length >=@wsize')\n",
    "             .assign(wstart= lambda x: x['min_end']-wsize, \n",
    "                     wend= lambda x: x['min_end']+wsize,\n",
    "                     name = lambda x: ['EL_' + str(i) for i in range(len(x.index))])\n",
    "             .reset_index(drop=True)\n",
    "             .assign(score=EL_score)\n",
    "             .loc[:,['seqid', 'wstart', 'wend', 'name', 'score', 'strand']]\n",
    "            )\n",
    "\n",
    "start_longer_all= (ref_gtf\n",
    "                   .query('type == \"exon\"')\n",
    "                   .groupby(['seqid','strand', 'end'], as_index=False)\n",
    "                   .agg({'start':['min', 'max', 'nunique']})\n",
    "                   .reset_index(drop=True)\n",
    "                  )\n",
    "start_longer_all.columns=['seqid', 'strand', 'end', 'min_start', 'max_start','count' ]\n",
    "start_longer_all=(start_longer_all\n",
    "                  .assign(short_length= lambda x: x['end'] -x['max_start'], \n",
    "                          long_length= lambda x: x['max_start']-x['min_start'])\n",
    "                  .query('count > 1')\n",
    "                 )\n",
    "start_longer= (start_longer_all\n",
    "               .query(\"count == 2 & short_length>= @wsize & long_length >= @wsize\")\n",
    "               .assign(wstart= lambda x: x['max_start']- wsize, \n",
    "                       wend= lambda x: x['max_start'] + wsize , \n",
    "                       name = lambda x: ['SL_' + str(i) for i in range(len(x.index))])\n",
    "               .reset_index(drop=True)\n",
    "               .assign(score=SL_score)\n",
    "               .loc[:,['seqid', 'wstart', 'wend', 'name', 'score', 'strand']]\n",
    "              )\n",
    "alt_spliced_windows=pd.concat([end_longer, start_longer]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vinayswamy/anaconda3/lib/python3.6/site-packages/pybedtools/bedtool.py:3439: FutureWarning: read_table is deprecated, use read_csv instead, passing sep='\\t'.\n",
      "  return pandas.read_table(self.fn, *args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "#********BUG anti_joins are not in pandas (SAD) and the method I'm using can sometimes coerce int64 to floats, which makes bedtools wig out **********************# \n",
    "'''\n",
    "remove any exons got used above using for start/end longer (hence the above problem with antijoins)\n",
    "antijoin again with bedtools to be real sure \n",
    "\n",
    "every exon in below table doesn't get longer/shorter and doesn't overlap with any regions in table above\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "exon_no_change= (ref_gtf #first, anti_join out known exon locations.\n",
    "                   .query('type == \"exon\"').loc[:,['seqid', 'strand', 'start', 'end']]\n",
    "                   .merge(end_longer_all.loc[:,['seqid','strand', 'start']],\n",
    "                          how='outer',indicator=True)\n",
    "                   .query('_merge ==  \"left_only\"')\n",
    "                   .drop(columns=['_merge'])\n",
    "                   .assign(start= lambda x: x['start'].astype(np.int64),\n",
    "                            end= lambda x: x['end'].astype(np.int64))\n",
    "                   .merge(start_longer_all.loc[:,['seqid','strand','end']], \n",
    "                          how='outer', indicator=True)\n",
    "                   .query('_merge == \"left_only\"')\n",
    "                   .drop(columns=['_merge'])\n",
    "                   .assign(start= lambda x: x['start'].astype(np.int64), \n",
    "                           end= lambda x: x['end'].astype(np.int64),\n",
    "                           name= 'nc', score=I_score)\n",
    "                   .loc[:,['seqid', 'start', 'end', 'name', 'score', 'strand']]\n",
    "                   # I'm concerned that 2 exons might overlap but not share the same start/end so\n",
    "                   # so also going to subtract out any previous windows.\n",
    "                   # make sure to keep only exons that are long enough for our window size.\n",
    "                   .pipe(BedTool.from_dataframe)\n",
    "                   .intersect(alt_spliced_windows.pipe(BedTool.from_dataframe),\n",
    "                            s=True, loj=True)\n",
    "                   .to_dataframe()\n",
    "                   .rename(columns={'chrom':'seqid'})\n",
    "                   .assign(length= lambda x: x['end']-x['start'])\n",
    "                   .query('length >=@wsize & thickEnd == -1 ' )\n",
    "                   .reset_index(drop=True)\n",
    "                   .loc[:,['seqid', 'start', 'end', 'name', 'score', 'strand']]\n",
    "                )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vinayswamy/anaconda3/lib/python3.6/site-packages/pybedtools/bedtool.py:3439: FutureWarning: read_table is deprecated, use read_csv instead, passing sep='\\t'.\n",
      "  return pandas.read_table(self.fn, *args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seqid</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>name</th>\n",
       "      <th>score</th>\n",
       "      <th>strand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chr1</td>\n",
       "      <td>450703</td>\n",
       "      <td>451697</td>\n",
       "      <td>nc</td>\n",
       "      <td>555</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chr1</td>\n",
       "      <td>923928</td>\n",
       "      <td>924948</td>\n",
       "      <td>nc</td>\n",
       "      <td>555</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>chr1</td>\n",
       "      <td>955923</td>\n",
       "      <td>956013</td>\n",
       "      <td>nc</td>\n",
       "      <td>555</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>chr1</td>\n",
       "      <td>953782</td>\n",
       "      <td>953892</td>\n",
       "      <td>nc</td>\n",
       "      <td>555</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>chr1</td>\n",
       "      <td>951127</td>\n",
       "      <td>951238</td>\n",
       "      <td>nc</td>\n",
       "      <td>555</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   seqid   start     end name  score strand\n",
       "0   chr1  450703  451697   nc    555      -\n",
       "1   chr1  923928  924948   nc    555      +\n",
       "95  chr1  955923  956013   nc    555      -\n",
       "96  chr1  953782  953892   nc    555      -\n",
       "97  chr1  951127  951238   nc    555      -"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "split the no change exons into 2 tables, one to use to make the no-change exon junction class, and one to use to make exon/intron classes\n",
    "\n",
    "'''\n",
    "dfs=len(exon_no_change.index)\n",
    "spl=np.array(bool_to_split(dfs))\n",
    "exons_for_junc=exon_no_change.iloc[spl].reset_index(drop=True)\n",
    "#junction set first \n",
    "spl_junc=np.array(bool_to_split(len(exons_for_junc.index)))\n",
    "junc_sl=(exons_for_junc\n",
    "         .iloc[spl_junc]\n",
    "         .reset_index(drop=True)\n",
    "         .assign(wstart =lambda x: x['start'] -wsize, \n",
    "                wend=lambda x: x['start']+wsize, \n",
    "                name=lambda x: ['ref_SL_'+str(i) for i in range(len(x.index))],\n",
    "                score=R_SL_score)\n",
    "         .loc[:,['seqid', 'wstart', 'wend', 'name', 'score', 'strand']]\n",
    "        )\n",
    "\n",
    "junc_el=(exons_for_junc\n",
    "         .iloc[~spl_junc]\n",
    "         .reset_index(drop=True)\n",
    "         .assign(wstart=lambda x: x['end'] -wsize, \n",
    "                 wend=lambda x: x['end']+wsize, \n",
    "                 name =lambda x: ['ref_EL_' + str(i) for i in range(len(x.index))],\n",
    "                 score=R_EL_score)\n",
    "         .loc[:,['seqid', 'wstart', 'wend', 'name', 'score', 'strand']]\n",
    "        )\n",
    "\n",
    "\n",
    "ref_altSplice_windows=pd.concat([junc_el, junc_sl]).reset_index(drop=True)\n",
    "\n",
    "#exon_no_change for sure does not overlap at all with with alt_spliced_windows, but it may overlap with ref_alt_windows, so going to anti_join that bish again.\n",
    "exons_for_exon=(exon_no_change\n",
    "                .iloc[~spl]\n",
    "                .reset_index(drop=True)\n",
    "                .pipe(BedTool.from_dataframe)\n",
    "                .intersect(ref_altSplice_windows.pipe(BedTool.from_dataframe),\n",
    "                          s=True, loj=True)\n",
    "                .to_dataframe()\n",
    "                .rename(columns={'chrom':'seqid'})\n",
    "                .query('thickEnd == -1 ')\n",
    "                .loc[:,['seqid', 'start', 'end', 'name', 'score', 'strand']]\n",
    "               )\n",
    "exons_for_exon.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vinayswamy/anaconda3/lib/python3.6/site-packages/pybedtools/bedtool.py:3439: FutureWarning: read_table is deprecated, use read_csv instead, passing sep='\\t'.\n",
      "  return pandas.read_table(self.fn, *args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Now need to get regions of intronic coverage\n",
    "subtract out all known exons from all transcripts, but pad the exons on wither end, such that pad > wsize. This way we are for sure that the intronic region over lap with none of our previous windows\n",
    "    - cant overlap with alt_splcied exons, bc window < long exon end. but fo the ref ones, the pad takes care of it.\n",
    "'''\n",
    "pad=wsize+5\n",
    "ref_txs=(ref_gtf\n",
    "         .query('type == \"transcript\"')\n",
    "         .loc[:,['seqid', 'start','end','transcript_id','score','strand']]\n",
    "         .assign(score=1000)\n",
    "         .reset_index(drop=True)\n",
    "        )\n",
    "\n",
    "ref_exons=(ref_gtf\n",
    "           .query('type == \"exon\"')\n",
    "           .loc[:,['seqid', 'start','end','transcript_id','score','strand']]\n",
    "           .assign(score=1000, \n",
    "                   start= lambda x: x['start'] -pad, \n",
    "                   end = lambda x: x['end'] +pad)\n",
    "           .reset_index(drop=True)\n",
    "          )\n",
    "\n",
    "introns=(ref_txs\n",
    "         .pipe(BedTool.from_dataframe)\n",
    "         .subtract(ref_exons.pipe(BedTool.from_dataframe), \n",
    "                   s=True)\n",
    "         .to_dataframe()\n",
    "         .assign(length=lambda x: x['end']-x['start'])\n",
    "         .query('length >= @wsize*4')# lets make sure were picking from bigger introns\n",
    "         .rename(columns={'chrom':'seqid'})\n",
    "         .reset_index(drop=True)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_random_window(ser, ws=wsize *2):\n",
    "    start=ser[1]\n",
    "    max_wend=ser[2]-ws\n",
    "    wstart=rd.randint(start, max_wend)\n",
    "    wend=wstart+ws\n",
    "    return((wstart, wend))\n",
    "intron_windows=(introns\n",
    "                .apply(make_random_window,axis=1, result_type='expand')\n",
    "                .rename(columns={0:'wstart', 1:'wend'})\n",
    "                .merge(introns,how='left', left_index=True, right_index=True)\n",
    "                .loc[:,['seqid', 'wstart', 'wend', 'name', 'score', 'strand']]\n",
    "                .assign(name = lambda x: ['intron_' + str(i) for i in range(len(x.index))],\n",
    "                        score=I_score)\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exon for exon does not overlap with either ref_alt or alt, so don't need to worry about that\n",
    "#also cannot overlap with intron version based on above logic, so don't worry about that either\n",
    "exon_windows= (exons_for_exon.reset_index(drop=True)\n",
    "                .assign(name='x', \n",
    "                        score=E_score,\n",
    "                        length=lambda x: x['end'] - x['start'])\n",
    "                .query('length >= @wsize*2 +1 ') # remove potential windows with\n",
    "              )\n",
    "exon_windows= (exon_windows\n",
    "                .apply(make_random_window, axis=1, result_type='expand')\n",
    "                .rename(columns={0:'wstart', 1:'wend'})\n",
    "                .merge(exon_windows, left_index=True, right_index=True)\n",
    "                .loc[:,['seqid', 'wstart', 'wend', 'name', 'score', 'strand']]\n",
    "                .assign(name=lambda x: ['exon_'+str(i) for i in range(len(x.index))])\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_samps=min(alt_spliced_windows.shape[0], ref_altSplice_windows.shape[0], \n",
    "              intron_windows.shape[0], exon_windows.shape[0])\n",
    "complete_bed=(pd.concat([alt_spliced_windows, \n",
    "                         ref_altSplice_windows.sample(min_samps), \n",
    "                         intron_windows.sample(min_samps), \n",
    "                         exon_windows.sample(min_samps)\n",
    "                        ])\n",
    "              .reset_index(drop=True)\n",
    "             )\n",
    "bad=complete_bed.assign(length= lambda x:x['wend']-x['wstart']).query('length<@wsize*2').shape\n",
    "if bad[0] >0:\n",
    "    print('Warning: {} rows are less than minimum window size')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_bed.to_csv(out_bed_file, header=False, index=False, sep='\\t')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
